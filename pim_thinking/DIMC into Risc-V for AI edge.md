https://arxiv.org/pdf/2602.01827

217 倍加速与 137GOP/s 峰值算力！数字存内计算与 RISC-V 向量架构的流水线级创新集成，突破边缘 AI 计算极限

在人工智能向边缘设备全面渗透的今天，传统的计算架构正面临着前所未有的挑战。随着 AI 模型复杂度的指数级增长与硬件性能提升速度之间的差距日益扩大，单纯依靠制程进步与架构微调【已无法满足】边缘设备对高能效、低延迟 AI 推理的需求。

-----------------------------------------------------------------------------------------
# 论文详细分析：RISC-V向量架构中的DIMC流水线集成

## 1. 基本信息

**标题**: In-Pipeline Integration of Digital In-Memory-Computing into RISC-V Vector Architecture to Accelerate Deep Learning  
**作者**: 
- Tommaso Spagnolo, Cristina Silvano (Politecnico di Milano, Italy)
- Riccardo Massa, Filippo Grillotti, Giuseppe Desoli (STMicroelectronics, Milan, Italy)
- Thomas Boesch (STMicroelectronics, Geneva, Switzerland)

**发表**: arXiv:2602.01827v1 [cs.AR], February 2026  
**核心主题**: AI加速器、RISC-V架构、指令集扩展、数字存内计算、向量处理器

---

## 2. 研究背景与动机

### 2.1 技术趋势与挑战
- **模型复杂度增长**: 自2012年AlexNet以来，AI模型参数量每年翻倍
- **硬件性能鸿沟**: FP32 TFLOP/s仅年增长约30%，传统架构无法满足需求
- **边缘计算需求**: 低延迟、高能效、数据隐私推动本地推理，但面临严格的功耗和内存约束

### 2.2 内存墙问题
- 数据移动能耗比计算能耗高数个数量级（DRAM访问 vs MAC运算）
- 传统加速器受限于内存带宽，特征图、权重和中间结果在内存层次结构间频繁搬运

### 2.3 存内计算（IMC）分类
| 类型 | 技术 | 优势 | 劣势 |
|------|------|------|------|
| **模拟IMC (AIMC)** | ReRAM, PCM等新兴非易失性存储 | &gt;1000 TOPS/W能效（低精度） | 可靠性、精度问题，限制在对精度要求高的任务 |
| **数字IMC (DIMC)** | 数字SRAM阵列 | 确定性行为、高精度、CMOS兼容 | 能效相对较低（10-300 TOPS/W） |

### 2.4 集成方式对比
- **松耦合**: IMC作为独立加速器，通过I/O总线访问，可扩展但通信开销大
- **紧耦合**: IMC嵌入流水线或靠近内存，通过ISA扩展直接访问，单周期延迟但增加设计复杂度

---

## 3. 核心贡献

本文提出**首个**将DIMC单元作为功能单元（FU）紧密集成到RISC-V向量处理器流水线中的架构：

1. **架构创新**: 在向量执行阶段（vEX）集成DIMC单元作为并行执行通道，实现指令级控制
2. **ISA扩展**: 设计4条自定义向量指令（DL.I, DL.M, DC.P, DC.F），兼容RISC-V向量标准，支持灵活的数据流控制
3. **性能验证**: 在工业级RISC-V向量核心上实现，ResNet-50达到137 GOPS峰值性能，相比基线加速217倍

---

## 4. 架构设计详解

### 4.1 基线平台
- **ISA**: RISC-V Vector Extension (Zve32x profile)
- **参数**: VLEN = 64, ELEN = 32
- **基础**: 工业级RVV实现（基于STMicroelectronics的STRiVe2.4 CPU）

### 4.2 DIMC单元架构
基于ISSCC 2023发表的DIMC设计（参考文献[9]）：

**存储组织**:
- 总容量: **32 KiB**
- 组织方式: 32行 × 1024位/行（用于存储卷积核权重）
- 输入缓冲: 1024位（存储特征数据）

**计算能力**:
- 子阵列结构: 多个8T 1R1W（1读1写）位单元子阵列
- 并行度: **256个并行的4-bit有符号/无符号MAC运算/周期**
  - 由4个并行子阵列组成，每子阵列64个MAC
- 可重配置: 支持512×2-bit或1024×1-bit运算（精度-能效权衡）
- 累加器: 共享累加流水线，支持24-bit部分和
- 激活函数: 可选ReLU单元

**接口**:
- 内存接口: 256位/周期读写
- 数据格式: 24-bit部分结果，最终输出量化至1/2/4-bit

### 4.3 流水线集成

**关键设计决策**:
- DIMC作为独立功能单元，与标准向量单元并行执行
- 所有数据交换通过向量寄存器文件（VRF）路由，避免内存一致性问题
- 利用RISC-V向量的数据重排能力预处理不规则张量（膨胀、分组卷积等）

---

## 5. 指令集架构（ISA）扩展

### 5.1 设计原则
- 映射到RISC-V **custom-0**空间（保留给非标准扩展）
- 兼容现有向量指令编码
- 支持细粒度控制：数据移动、执行顺序、结果处理

### 5.2 四条自定义指令

#### 1. DL.I (DIMC Input Buffer Load)
- **功能**: 从向量寄存器文件（VRF）加载数据到DIMC输入缓冲（1024-bit）
- **操作**: 从vs1开始的nvec个连续VRF寄存器读取64-256位数据
- **字段**: 
  - `sec`: 指定写入输入缓冲的4个256-bit扇区之一
  - `mask`: 有效位掩码

#### 2. DL.M (DIMC Memory Load)
- **功能**: 加载权重到DIMC内存阵列（32行）
- **操作**: 类似DL.I，但增加`m_row`字段指定目标行（0-31）

#### 3. DC.P (DIMC Compute & Partial Sum Store)
- **功能**: 执行内存内MAC运算并存储部分和
- **操作**: 
  - 在输入缓冲与指定内存行（m_row）之间执行MAC
  - 从vs1指定的半寄存器（由`sh`选择）读取24-bit部分和输入
  - 24-bit结果写入vd指定的半寄存器（由`dh`选择）
- **精度**: 24-bit累加

#### 4. DC.F (DIMC Compute & Final Sum Store)
- **功能**: 最终MAC运算 + ReLU激活 + 量化存储
- **操作**:
  - 执行与DC.P相同的MAC运算
  - 应用ReLU激活函数
  - 量化为1/2/4-bit，紧凑打包存储
  - 写入vd寄存器的指定字节（由`dh`和`bidx`索引）
- **数据打包**: 两个4-bit结果打包成一个字节（奇数结果时末半字节未使用）

### 5.3 编码细节
- 使用标准RISC-V向量指令格式（mask, nvec, vs1, vd等字段）
- 自定义字段包括: `m_row`（行地址）、`sec`（扇区）、`sh/dh`（半字选择）、`bidx`（字节索引）

---

## 6. 详细技术对比分析

### 6.1 现有技术分类框架

当前IMC与RISC-V集成的工作可从两个维度分类：
1. **处理器类型**: 标量（Scalar）vs 向量（Vector）核心
2. **集成策略**: 松耦合（Loosely-coupled）vs 紧耦合（Tightly-coupled）

| 集成策略 | 通信机制 | 延迟 | 灵活性 | 适用场景 |
|---------|---------|------|--------|----------|
| **松耦合** | 内存映射I/O、DMA、专用总线 | 高（数十周期） | 硬件简单，软件控制粗粒度 | 独立加速器、大批量数据 |
| **紧耦合** | 流水线内集成、寄存器文件共享 | 低（单周期） | 硬件复杂，指令级细粒度控制 | 低延迟、频繁交互、异构计算 |

### 6.2 多维度性能对比表

| 架构 | 核心类型 | 集成方式 | 存储技术 | 存储容量 | 频率 | 峰值性能 | 能效 | 精度支持 | 标准化性能* |
|------|---------|----------|----------|----------|------|----------|------|----------|-------------|
| **CIMR-V** [16] | 标量 | 松耦合 | 10T SRAM | 64 KB | 50 MHz | 26.2 TOPS@INT1 | - | 1-bit | ~2.6 TOPS@INT4 |
| **AI-PiM** [12] | 标量 | 紧耦合(流水线内) | 8T SRAM | 500 B | - | - | - | - | - |
| **VPU-CIM** [15] | 向量 | 松耦合 | RRAM | 8 KB | 25 MHz | - | 33.98 TOPS/W | 1-4 bit | - |
| **Vecim** [13] | 向量 | 紧耦合(寄存器文件) | 8T SRAM | - | 250 MHz | 31.8 GOPS@INT8 | 289.13 GOPS/W | INT8/BF16/FP16 | ~63.6 GOPS@INT4 |
| **RDCIM** [14] | 标量 | 紧耦合 | 8T SRAM | 64 KB | 200 MHz | - | 66.3 TOPS/W@4b | 4/8/12/16-bit | - |
| **本文工作** | **向量** | **紧耦合(流水线内)** | **8T SRAM** | **4 KB** | **500 MHz** | **137 GOPS@INT4** | - | **INT4/2/1** | **137 GOPS@INT4** |

*注：标准化性能按INT4精度和500MHz频率归一化，便于公平对比。能效数据论文未全部提供。

### 6.3 代表性工作深度解析

#### A. 紧耦合标量架构：AI-PiM [12]
- **架构**: 扩展RV64IMC ISA，将PiM单元集成在处理器流水线内
- **性能**: 矩阵向量乘法加速17.63倍，MLPerf Tiny平均提升2.74倍
- **局限**: 
  - 基于标量流水线，缺乏向量化能力，无法充分利用数据级并行（DLP）
  - 存储容量仅500B，限制单层网络规模
  - 未报告绝对峰值性能（GOPS）

#### B. 紧耦合向量架构（寄存器文件级）：Vecim [13]
- **架构**: 将8T SRAM-based CIM作为**向量寄存器文件（VRF）**集成，而非独立功能单元
- **性能**: 250MHz下31.8 GOPS@INT8，能效289.13 GOPS/W
- **优势**: 支持多精度（INT8/BF16/FP16），利用向量ISA
- **局限**: 
  - 设计重心在寄存器文件集成，而非功能单元扩展
  - 计算灵活性受限，难以支持 diverse computational flows（如复杂的数据流控制、部分和重用）
  - INT8性能折算为INT4约63.6 GOPS，低于本文的137 GOPS

#### C. 紧耦合标量架构：RDCIM [14]
- **架构**: 全数字CIM处理器，通过扩展指令精细控制，采用边界累加（AOMB）和多精度自适应累加器（MPAA）
- **性能**: 4-bit模式下66.3 TOPS/W，8-bit模式下16.6 TOPS/W
- **优势**: 支持4/8/12/16-bit高精度，低面积开销
- **局限**: 
  - 仍为标量流水线，无法处理向量级并行工作负载
  - 未报告绝对吞吐量（GOPS），仅报告能效（TOPS/W）

#### D. 松耦合向量架构：VPU-CIM [15]
- **架构**: 基于RRAM的CIM，通过向量ISA扩展控制，但CIM操作与主流水线解耦
- **性能**: 130nm工艺下33.98 TOPS/W，支持1-4bit可变精度
- **局限**: 
  - 松耦合导致额外通信开销，缺乏细粒度流水线级控制
  - 频率仅25MHz，性能受限
  - 未报告绝对GOPS数值

#### E. 松耦合标量架构：CIMR-V [16]
- **架构**: 10T SRAM数字CIM引擎，配合卷积和池化流水线，专用指令控制
- **性能**: TSMC 28nm，50MHz，INT1精度下26.2 TOPS
- **应用**: 关键词识别任务
- **局限**: 
  - 卸载模型（offloading）引入延迟，AI工作负载灵活性受限
  - 标量核心限制并行度
  - 归一化至INT4和500MHz后性能仅约2.6 TOPS，远低于本文

### 6.4 技术路线差异分析

#### 紧耦合 vs 松耦合：控制粒度与延迟
- **松耦合方案**（CIMR-V, VPU-CIM）将IMC视为内存映射外设：
  - 需通过Load/Store或DMA传输数据，延迟数十周期
  - 适合粗粒度任务卸载（如整层网络计算），不适合细粒度数据交互
  
- **紧耦合方案**（AI-PiM, RDCIM, Vecim, 本文）：
  - AI-PiM和RDCIM：标量级紧耦合，指令级控制但无向量并行
  - Vecim：向量级紧耦合，但集成在寄存器文件层，数据流受限
  - **本文**：向量级紧耦合，集成在执行阶段（vEX）作为独立功能单元，支持与其他向量单元并行执行

#### 标量 vs 向量：并行能力
- **标量IMC**（AI-PiM, RDCIM, CIMR-V）：单指令单数据（SISD），依赖指令级并行（ILP），适合控制密集型任务，计算密度低
- **向量IMC**（Vecim, VPU-CIM, 本文）：单指令多数据（SIMD），利用数据级并行（DLP），适合CNN等规则数据并行工作负载

#### 存储集成层次
| 层次 | 代表工作 | 特点 | 延迟 |
|------|---------|------|------|
| **片外/总线** | VPU-CIM, CIMR-V | 通过总线访问，容量大 | 高 |
| **寄存器文件** | Vecim | 作为VRF，读写直接 | 中 |
| **执行阶段** | **本文** | 作为FU，与VRF紧连 | **低** |
| **流水线内** | AI-PiM | 作为执行单元，但标量 | 低 |

### 6.5 本文工作的差异化优势

1. **首创性定位**：
   - 首个将DIMC作为**功能单元（FU）**集成在**向量处理器流水线**中的设计
   - 填补了"向量核心+紧耦合+执行级集成"的技术空白

2. **性能密度**：
   - **137 GOPS**的峰值性能远超同类向量方案（Vecim: 63.6 GOPS标准化后）
   - 仅用**4KB**存储容量达到此性能，性能/容量比（34.25 GOPS/KB）远高于CIMR-V（0.04 GOPS/KB）和RDCIM（未报告，但64KB存储无对应高性能）

3. **能效与精度权衡**：
   - 支持INT4/2/1动态可重构，适应不同精度需求
   - 数字IMC（DIMC）确保确定性行为和鲁棒性，优于RRAM/VPU-CIM的模拟特性

4. **软件可控性**：
   - 4条自定义指令提供汇编级灵活控制，支持：
     - 内核动态加载（32行内存管理）
     - 部分和流水（DC.P指令的24-bit累加链）
     - 结果紧凑打包（DC.F的字节级索引）
   - 相比固定功能加速器（如CIMR-V的专用卷积流水线），支持更广泛的网络拓扑（ResNet, EfficientNet, MobileNet等）

5. **鲁棒性**：
   - 在超出硬件容量（内核>1024bit，通道>32）时，通过软件分块（tiling）和分组（grouping）仍保持100倍+加速
   - 松耦合方案在类似约束下通常需要重新配置硬件或承受更高性能损失

### 6.6 局限性对比

| 局限 | 本文工作 | 其他工作 |
|------|---------|----------|
| **存储容量** | 4KB较小（但性能密度高） | CIMR-V(64KB), RDCIM(64KB)更大，但利用率低 |
| **精度** | 最高INT4 | Vecim(INT8/FP16), RDCIM(16-bit)支持更高 |
| **能效数据** | 未报告（计划未来工作） | Vecim, RDCIM, VPU-CIM均有详细能效 |
| **多Tile扩展** | 单Tile评估 | 未涉及多核扩展 |

---

## 7. 实验评估

### 7.1 实验设置
- **仿真**: 周期近似模拟框架，建模流水线互连和DIMC集成
- **工艺**: P18 CMOS（STMicroelectronics）
- **频率**: 500 MHz
- **基准测试**: ResNet-50（提取卷积层和全连接层）
- **对比基线**: 工业级RISC-V向量核心（无DIMC）

**假设与约束**:
- 未考虑双发射向量指令（保守估计）
- 固定延迟外部内存模型
- 数据加载保守假设（未充分利用数据重用）
- 基线支持8-bit，DIMC支持最高4-bit
- 单内核限制1024-bit，最多32个内核存储

### 7.2 性能指标

#### 吞吐量（GOPS）
- **峰值**: **137 GOPS**（INT4精度，500MHz）
- **各层表现**（见图5）:
  - CONV1: 90 GOPS
  - CONV3_1: 137 GOPS（峰值）
  - CONV4_2: 132 GOPS
  - FC层: 11 GOPS（受限于数据局部性）

#### 利用率分析（见图6）
- **计算占比**: 48%-86%（大部分时间用于MAC运算）
- **加载/存储开销**: 低至5-48%，证明紧耦合集成有效减少数据移动

#### 加速比（见图7）
- **原始加速比**: 最高**217倍**（CONV3_1），平均超过100倍
- **面积标准化加速比**: 最高**96倍**（CONV3_2），平均50倍以上
- 即使考虑DIMC额外硬件成本，性能增益依然显著

### 7.3 架构约束下的鲁棒性

#### 内核分块（Tiling）
当单内核超过1024-bit限制时（见图8）:
- 768-bit内核: 164倍加速
- 1024-bit（极限）: 198倍加速  
- 1152-bit（需分块）: 降至101倍加速，但仍维持优势

#### 分组卷积（Grouping）
当输出通道（OCH）超过32限制时（见图9）:
- 16通道: 95倍加速
- 32通道（极限）: 124倍加速
- 64通道（需分组）: 仍保持124倍加速

**结论**: 即使在超出硬件容量、需要频繁内核切换或次优内存映射的场景下，架构仍保持高加速比，证明其适应性。

### 7.4 跨模型泛化
测试覆盖7种CNN架构（AlexNet, VGG16, ResNet, Inception, DenseNet, EfficientNet, MobileNet）的**450+卷积层**，DIMC增强系统在所有配置下均优于基线。

---

## 8. 技术洞察与创新点

### 8.1 软件定义数据流
通过扩展ISA（而非固定逻辑），允许汇编级灵活控制：
- 内核加载策略（预加载 vs 即时加载）
- 特征图遍历顺序（行优先/列优先/窗口滑动）
- 精度动态切换（1/2/4-bit）

### 8.2 向量核心作为"数据操纵器"
RISC-V向量单元不仅用于计算，更用于：
- 张量重排（reshape/transpose）
- 数据打包/解包
- 不规则卷积（空洞、分组）的预处理
这种分工避免额外胶水逻辑，仅需VRF中的 modest cycle overhead。

### 8.3 部分和与最终结果的分离处理
- **DC.P**: 处理中间累加（24-bit宽），支持多周期卷积的流水线处理
- **DC.F**: 处理最终输出（量化+激活），紧凑打包减少VRF压力

---

## 9. 局限性与未来工作

### 当前限制
1. **单 tile 设计**: 仅评估单个DIMC单元，未探索多tile扩展
2. **能耗数据**: 未报告RTL级功耗估算（计划在未来工作中补充）
3. **编译器支持**: 当前依赖手工汇编或工具链生成指令流，未集成高级编译器
4. **精度限制**: 当前DIMC仅支持最高4-bit（基线支持8-bit），影响某些应用

### 未来方向
- 多tile架构的互连和并行策略
- 支持更高精度（8-bit）的DIMC设计
- 自动化编译工具链（TensorFlow Lite等前端支持）
- 其他工作负载（Transformer, DSP算法）的评估

---

## 10. 结论

本文提出的架构代表了**边缘AI加速器设计**的重要进展：

1. **架构范式**: 证明了在RISC-V向量流水线内紧密集成DIMC的可行性，兼顾高性能与可编程性
2. **效率**: 通过4条自定义指令实现精细控制，达到137 GOPS峰值，计算占比>70%
3. **实用性**: 在严格硬件约束下（4KB存储，单tile）仍维持200倍+加速，面积标准化增益50倍+
4. **灵活性**: 与固定功能加速器不同，该设计通过向量ISA的可编程性适应多样化CNN拓扑

这项工作为下一代边缘AI设备提供了可扩展、自适应的加速器蓝图，特别是在需要平衡性能、能效和模型多样性的场景中具有重要价值。

---

## 关键数据速查

- **峰值性能**: 137 GOPS @ INT4, 500MHz
- **最大加速比**: 217×（vs 基线RVV核心）
- **面积标准化加速比**: 96×
- **ISA扩展**: 4条指令（DL.I, DL.M, DC.P, DC.F）
- **存储容量**: 32KB权重存储 + 1KB输入缓冲
- **并行MAC**: 256× 4-bit MAC/周期
- **工艺**: 18nm FD-SOI
- **vs 现有技术**: 相比Vecim提升2.15倍，相比CIMR-V提升52倍（标准化后）